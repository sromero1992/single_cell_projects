{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "700ede50-80d5-4f42-8eb2-aba805b99be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit_algorithms.utils import algorithm_globals\n",
    "\n",
    "algorithm_globals.random_seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f4c8328-93c1-4da3-8686-77372d4bf1ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\envs\\venv_qml\\lib\\site-packages\\qiskit\\visualization\\circuit\\matplotlib.py:266: FutureWarning: The default matplotlib drawer scheme will be changed to \"iqp\" in a following release. To silence this warning, specify the current default explicitly as style=\"clifford\", or the new default as style=\"iqp\".\n",
      "  self._style, def_font_ratio = load_style(self._style)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 352.675x117.056 with 1 Axes>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2.1 The EstimatorQNN  takes in a parametrized quantum circuit as input\n",
    "# optional QM observable\n",
    "# The EstimatorQNN also accepts lists of observables to construct more complex QNNs.\n",
    "from qiskit.circuit import Parameter\n",
    "from qiskit import QuantumCircuit\n",
    "\n",
    "params1 = [Parameter(\"input1\"), Parameter(\"weight1\")]\n",
    "qc1 = QuantumCircuit(1)\n",
    "qc1.h(0)\n",
    "qc1.ry(params1[0], 0)\n",
    "qc1.rx(params1[1], 0)\n",
    "qc1.draw(\"mpl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49faf705-43a3-4f5e-95d1-a408aa765fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default observable Z^(X)n\n",
    "# Here we change to Y^(X)n  for n qubits\n",
    "from qiskit.quantum_info import SparsePauliOp\n",
    "\n",
    "observable1 = SparsePauliOp.from_list([(\"Y\" * qc1.num_qubits, 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b29bf04-c49b-4111-a0b3-842b0c57ef3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<qiskit_machine_learning.neural_networks.estimator_qnn.EstimatorQNN at 0x1bef1baf970>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here estimator is default because is local simulation\n",
    "# estimator has to be declared for cloud or Aer\n",
    "from qiskit_machine_learning.neural_networks import EstimatorQNN\n",
    "\n",
    "estimator_qnn = EstimatorQNN(\n",
    "    circuit=qc1, observables=observable1, input_params=[params1[0]], weight_params=[params1[1]]\n",
    ")\n",
    "estimator_qnn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bd6d816-5f9e-45f8-b2e1-41bbd7fb87aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input parameters: ['input[0]', 'input[1]']\n",
      "weight parameters: ['weight[0]', 'weight[1]', 'weight[2]', 'weight[3]']\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 538.128x200.667 with 1 Axes>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sampler Qnn class 2.2\n",
    "# Since it directly consumes samples from measuring qc, thus do not require custom observable\n",
    "# we will have two input parameters and four trainable weights that parametrize a two-local circuit.\n",
    "from qiskit.circuit import ParameterVector\n",
    "\n",
    "inputs2 = ParameterVector(\"input\", 2)\n",
    "weights2 = ParameterVector(\"weight\", 4)\n",
    "print(f\"input parameters: {[str(item) for item in inputs2.params]}\")\n",
    "print(f\"weight parameters: {[str(item) for item in weights2.params]}\")\n",
    "\n",
    "qc2 = QuantumCircuit(2)\n",
    "qc2.ry(inputs2[0], 0)\n",
    "qc2.ry(inputs2[1], 1)\n",
    "qc2.cx(0, 1)\n",
    "qc2.ry(weights2[0], 0)\n",
    "qc2.ry(weights2[1], 1)\n",
    "qc2.cx(0, 1)\n",
    "qc2.ry(weights2[2], 0)\n",
    "qc2.ry(weights2[3], 1)\n",
    "\n",
    "qc2.draw(output=\"mpl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f57f094-6cda-4d59-b92b-95a65ec719cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<qiskit_machine_learning.neural_networks.sampler_qnn.SamplerQNN at 0x1bef279e5e0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we are choosing not to set the Sampler instance to the QNN and relying on the default.\n",
    "from qiskit_machine_learning.neural_networks import SamplerQNN\n",
    "\n",
    "sampler_qnn = SamplerQNN(circuit=qc2, input_params=inputs2, weight_params=weights2)\n",
    "sampler_qnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8190dc77-8db2-4da5-b060-f0a6595ff222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of input features for EstimatorQNN: 1 \n",
      "Input: [0.77395605]\n",
      "Number of trainable weights for EstimatorQNN: 1 \n",
      "Weights: [0.43887844]\n"
     ]
    }
   ],
   "source": [
    "# SamplerQNN accepts three more settings: input_gradients, interpret, and output_shape\n",
    "# 3. How to Run a Forward Pass\n",
    "estimator_qnn_input = algorithm_globals.random.random(estimator_qnn.num_inputs)\n",
    "estimator_qnn_weights = algorithm_globals.random.random(estimator_qnn.num_weights)\n",
    "print(\n",
    "    f\"Number of input features for EstimatorQNN: {estimator_qnn.num_inputs} \\nInput: {estimator_qnn_input}\"\n",
    ")\n",
    "print(\n",
    "    f\"Number of trainable weights for EstimatorQNN: {estimator_qnn.num_weights} \\nWeights: {estimator_qnn_weights}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a7b03df-d0da-4cc5-8036-961c48e87b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of input features for SamplerQNN: 2 \n",
      "Input: [0.85859792 0.69736803]\n",
      "Number of trainable weights for SamplerQNN: 4 \n",
      "Weights: [0.09417735 0.97562235 0.7611397  0.78606431]\n"
     ]
    }
   ],
   "source": [
    "sampler_qnn_input = algorithm_globals.random.random(sampler_qnn.num_inputs)\n",
    "sampler_qnn_weights = algorithm_globals.random.random(sampler_qnn.num_weights)\n",
    "print(\n",
    "    f\"Number of input features for SamplerQNN: {sampler_qnn.num_inputs} \\nInput: {sampler_qnn_input}\"\n",
    ")\n",
    "print(\n",
    "    f\"Number of trainable weights for SamplerQNN: {sampler_qnn.num_weights} \\nWeights: {sampler_qnn_weights}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "795f08fc-b7d8-43cd-8fb1-ee7c517a2c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward pass result for EstimatorQNN: [[0.2970094]]. \n",
      "Shape: (1, 1)\n"
     ]
    }
   ],
   "source": [
    "# Forward pass stage\n",
    "# the expected output shape for the forward pass is (1, num_qubits * num_observables) where 1 in our case is the number of samples\n",
    "estimator_qnn_forward = estimator_qnn.forward(estimator_qnn_input, estimator_qnn_weights)\n",
    "\n",
    "print(\n",
    "    f\"Forward pass result for EstimatorQNN: {estimator_qnn_forward}. \\nShape: {estimator_qnn_forward.shape}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8596f0d7-410b-4170-b8a0-bd06c30a54bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward pass result for SamplerQNN: [[0.01826527 0.25735654 0.5267981  0.19758009]].  \n",
      "Shape: (1, 4)\n"
     ]
    }
   ],
   "source": [
    "# The expected output shape for the forward pass is (1, 2**num_qubits)\n",
    "# With a custom interpret function, the output shape will be (1, output_shape)\n",
    "# for 1 number of samples\n",
    "sampler_qnn_forward = sampler_qnn.forward(sampler_qnn_input, sampler_qnn_weights)\n",
    "\n",
    "print(\n",
    "    f\"Forward pass result for SamplerQNN: {sampler_qnn_forward}.  \\nShape: {sampler_qnn_forward.shape}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63eeff6a-de93-46f9-80b7-7624bbb2d8d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward pass result for EstimatorQNN: [[0.2970094]\n",
      " [0.2970094]].  \n",
      "Shape: (2, 1)\n"
     ]
    }
   ],
   "source": [
    "# Batched forward pass\n",
    "# the expected output shape for the forward pass is (batch_size, num_qubits * num_observables)\n",
    "estimator_qnn_forward_batched = estimator_qnn.forward(\n",
    "    [estimator_qnn_input, estimator_qnn_input], estimator_qnn_weights\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Forward pass result for EstimatorQNN: {estimator_qnn_forward_batched}.  \\nShape: {estimator_qnn_forward_batched.shape}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4bc75ef-d314-4e7a-abef-3863d0897420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward pass result for SamplerQNN: [[0.01826527 0.25735654 0.5267981  0.19758009]\n",
      " [0.01826527 0.25735654 0.5267981  0.19758009]].  \n",
      "Shape: (2, 4)\n"
     ]
    }
   ],
   "source": [
    "# the expected output shape for the forward pass is (batch_size, 2**num_qubits)\n",
    "# With a custom interpret function, the output shape will be (batch_size, output_shape)\n",
    "sampler_qnn_forward_batched = sampler_qnn.forward(\n",
    "    [sampler_qnn_input, sampler_qnn_input], sampler_qnn_weights\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Forward pass result for SamplerQNN: {sampler_qnn_forward_batched}.  \\nShape: {sampler_qnn_forward_batched.shape}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "044d57d5-eb82-455a-9c36-a75800820f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input gradients for EstimatorQNN: None.  \n",
      "Shape: None\n",
      "Weight gradients for EstimatorQNN: [[[0.63272767]]].  \n",
      "Shape: (1, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "# 4. How to Run a Backward Pass\n",
    "# the backward pass returns a tuple (input_gradients, weight_gradients)\n",
    "# backward pass will only calculate gradients with respect to the weight parameters.\n",
    "# enable gradients with respect to the input parameters ------> qnn = ...QNN(..., input_gradients=True)\n",
    "# input gradients are required for the use of TorchConnector for PyTorch integration.\n",
    "### Estimator\n",
    "# shape (batch_size, num_qubits * num_observables, num_weights):\n",
    "estimator_qnn_input_grad, estimator_qnn_weight_grad = estimator_qnn.backward(\n",
    "    estimator_qnn_input, estimator_qnn_weights\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Input gradients for EstimatorQNN: {estimator_qnn_input_grad}.  \\nShape: {estimator_qnn_input_grad}\"\n",
    ")\n",
    "print(\n",
    "    f\"Weight gradients for EstimatorQNN: {estimator_qnn_weight_grad}.  \\nShape: {estimator_qnn_weight_grad.shape}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe3abd0f-3acc-466f-85b9-5660c1fa0853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input gradients for SamplerQNN: None.  \n",
      "Shape: None\n",
      "Weight gradients for SamplerQNN: [[[ 0.00606238 -0.1124595  -0.06856156 -0.09809236]\n",
      "  [ 0.21167414 -0.09069775  0.06856156 -0.22549618]\n",
      "  [-0.48846674  0.32499215 -0.32262178  0.09809236]\n",
      "  [ 0.27073021 -0.12183491  0.32262178  0.22549618]]].  \n",
      "Shape: (1, 4, 4)\n"
     ]
    }
   ],
   "source": [
    "# the expected output shape for the forward pass is (batch_size, 2**num_qubits, num_weights)\n",
    "# With a custom interpret function, the output shape will be (batch_size, output_shape, num_weights)\n",
    "\n",
    "sampler_qnn_input_grad, sampler_qnn_weight_grad = sampler_qnn.backward(\n",
    "    sampler_qnn_input, sampler_qnn_weights\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Input gradients for SamplerQNN: {sampler_qnn_input_grad}.  \\nShape: {sampler_qnn_input_grad}\"\n",
    ")\n",
    "print(\n",
    "    f\"Weight gradients for SamplerQNN: {sampler_qnn_weight_grad}.  \\nShape: {sampler_qnn_weight_grad.shape}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "660db7af-3fda-40a9-9dc3-f7a6190274a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable gradients\n",
    "estimator_qnn.input_gradients = True\n",
    "sampler_qnn.input_gradients = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "265b5c9b-2377-431b-92b0-66f0b7accbd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input gradients for EstimatorQNN: [[[0.3038852]]].  \n",
      "Shape: (1, 1, 1)\n",
      "Weight gradients for EstimatorQNN: [[[0.63272767]]].  \n",
      "Shape: (1, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "# the expected output shape for the input gradients is (batch_size, num_qubits * num_observables,\n",
    "estimator_qnn_input_grad, estimator_qnn_weight_grad = estimator_qnn.backward(\n",
    "    estimator_qnn_input, estimator_qnn_weights\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Input gradients for EstimatorQNN: {estimator_qnn_input_grad}.  \\nShape: {estimator_qnn_input_grad.shape}\"\n",
    ")\n",
    "print(\n",
    "    f\"Weight gradients for EstimatorQNN: {estimator_qnn_weight_grad}.  \\nShape: {estimator_qnn_weight_grad.shape}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c913cdcb-8273-414b-83b0-2e81939f0557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input gradients for SamplerQNN: [[[-0.05844702 -0.10621091]\n",
      "  [ 0.38798796 -0.19544083]\n",
      "  [-0.34561132  0.09459601]\n",
      "  [ 0.01607038  0.20705573]]].  \n",
      "Shape: (1, 4, 2)\n",
      "Weight gradients for SamplerQNN: [[[ 0.00606238 -0.1124595  -0.06856156 -0.09809236]\n",
      "  [ 0.21167414 -0.09069775  0.06856156 -0.22549618]\n",
      "  [-0.48846674  0.32499215 -0.32262178  0.09809236]\n",
      "  [ 0.27073021 -0.12183491  0.32262178  0.22549618]]].  \n",
      "Shape: (1, 4, 4)\n"
     ]
    }
   ],
   "source": [
    "# the expected output shape for the input gradients is (batch_size, 2**num_qubits, num_inputs)\n",
    "# With a custom interpret function, the output shape will be (batch_size, output_shape, num_inputs)\n",
    "sampler_qnn_input_grad, sampler_qnn_weight_grad = sampler_qnn.backward(\n",
    "    sampler_qnn_input, sampler_qnn_weights\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Input gradients for SamplerQNN: {sampler_qnn_input_grad}.  \\nShape: {sampler_qnn_input_grad.shape}\"\n",
    ")\n",
    "print(\n",
    "    f\"Weight gradients for SamplerQNN: {sampler_qnn_weight_grad}.  \\nShape: {sampler_qnn_weight_grad.shape}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c0dee38-e482-43dd-8cdc-7cafbfd8be32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward output for EstimatorQNN1: (1, 1)\n",
      "Forward output for EstimatorQNN2: (1, 2)\n",
      "Backward output for EstimatorQNN1: (1, 1, 1)\n",
      "Backward output for EstimatorQNN2: (1, 2, 1)\n"
     ]
    }
   ],
   "source": [
    "# pass lists of observables for more complex QNN architectures. \n",
    "observable2 = SparsePauliOp.from_list([(\"Z\" * qc1.num_qubits, 1)])\n",
    "\n",
    "estimator_qnn2 = EstimatorQNN(\n",
    "    circuit=qc1,\n",
    "    observables=[observable1, observable2],\n",
    "    input_params=[params1[0]],\n",
    "    weight_params=[params1[1]],\n",
    ")\n",
    "\n",
    "estimator_qnn_forward2 = estimator_qnn2.forward(estimator_qnn_input, estimator_qnn_weights)\n",
    "estimator_qnn_input_grad2, estimator_qnn_weight_grad2 = estimator_qnn2.backward(\n",
    "    estimator_qnn_input, estimator_qnn_weights\n",
    ")\n",
    "\n",
    "print(f\"Forward output for EstimatorQNN1: {estimator_qnn_forward.shape}\")\n",
    "print(f\"Forward output for EstimatorQNN2: {estimator_qnn_forward2.shape}\")\n",
    "print(f\"Backward output for EstimatorQNN1: {estimator_qnn_weight_grad.shape}\")\n",
    "print(f\"Backward output for EstimatorQNN2: {estimator_qnn_weight_grad2.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a26cf0f-1ee7-4c44-ae20-c50c7fb4a9be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward output for SamplerQNN1: (1, 4)\n",
      "Forward output for SamplerQNN2: (1, 2)\n",
      "Backward output for SamplerQNN1: (1, 4, 4)\n",
      "Backward output for SamplerQNN2: (1, 2, 4)\n"
     ]
    }
   ],
   "source": [
    "# Sampler \n",
    "# One common interpret method for SamplerQNN is the parity function\n",
    "# allows it to perform binary classification. \n",
    "#  output_shape is fixed to 2. Therefore, the expected forward and weight gradient shapes are (batch_size, 2) and (batch_size, 2, num_weights),\n",
    "parity = lambda x: \"{:b}\".format(x).count(\"1\") % 2\n",
    "output_shape = 2  # parity = 0, 1\n",
    "\n",
    "sampler_qnn2 = SamplerQNN(\n",
    "    circuit=qc2,\n",
    "    input_params=inputs2,\n",
    "    weight_params=weights2,\n",
    "    interpret=parity,\n",
    "    output_shape=output_shape,\n",
    ")\n",
    "\n",
    "sampler_qnn_forward2 = sampler_qnn2.forward(sampler_qnn_input, sampler_qnn_weights)\n",
    "sampler_qnn_input_grad2, sampler_qnn_weight_grad2 = sampler_qnn2.backward(\n",
    "    sampler_qnn_input, sampler_qnn_weights) \n",
    "\n",
    "print(f\"Forward output for SamplerQNN1: {sampler_qnn_forward.shape}\")\n",
    "print(f\"Forward output for SamplerQNN2: {sampler_qnn_forward2.shape}\")\n",
    "print(f\"Backward output for SamplerQNN1: {sampler_qnn_weight_grad.shape}\")\n",
    "print(f\"Backward output for SamplerQNN2: {sampler_qnn_weight_grad2.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ec9f97-71f1-4771-9b31-da0dc713253c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
